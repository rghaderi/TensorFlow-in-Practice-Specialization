{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "bd468572-8405-45dd-c146-7d357a702212"
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73c1e4c0-cd20-40be-99fb-ada7522e6fe0"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150,150,3),\n",
        "                                include_top = False,\n",
        "                                weights = None)# Your Code Here\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "   layer.trainable = False # Your Code Here\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-02 23:31:29--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  57.5MB/s    in 1.5s    \n",
            "\n",
            "2020-01-02 23:31:30 (57.5 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5235590e-0cee-4405-88f9-25b162efb9f6"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')# Your Code Here)\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output =  last_layer.output # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3df4ee5-48b7-46c2-82c9-d737931ec2fe"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)# Your Code Here)(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)# Your Code Here)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)# Your Code Here)(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x)# Your Code Here, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy',# Your Code Here, \n",
        "              metrics =['accuracy'])# Your Code Here)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "e0da58a3-913b-4c1d-ed2c-589b1aacf767"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-02 23:32:04--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   136MB/s    in 1.0s    \n",
            "\n",
            "2020-01-02 23:32:05 (136 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2020-01-02 23:32:06--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  42.2MB/s    in 0.3s    \n",
            "\n",
            "2020-01-02 23:32:06 (42.2 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5d98beff-f20a-4a0b-cee3-34654e4d0090"
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses/'# Your Code Here\n",
        "train_humans_dir = '/tmp/training/humans/'# Your Code Here\n",
        "validation_horses_dir = '/tmp/validation/horses/'# Your Code Here\n",
        "validation_humans_dir = '/tmp/validation/humans/'# Your Code Here\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)# Your Code Here\n",
        "train_humans_fnames = os.listdir(train_humans_dir)# Your Code Here\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)# Your Code Here\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)# Your Code Here\n",
        "\n",
        "print(len(train_horses_fnames))# Your Code Here)\n",
        "print(len(train_humans_fnames))# Your Code Here)\n",
        "print(len(validation_horses_fnames))# Your Code Here)\n",
        "print(len(validation_humans_fnames))# Your Code Here)\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH4xW12pECbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -r '/tmp/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "44573c7b-51be-45d5-de19-93d6cae5a80a"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.0,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   fill_mode = 'nearest')  # Your Code Here)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.0)# Your Code Here )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size =20,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    target_size = (150,150))# Your Code Here)     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size =20,\n",
        "                                                         class_mode = 'binary',\n",
        "                                                         target_size = (150,150))# Your Code Here)     \n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b90cb1fa-261a-40e0-b79c-b5021d543100"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback() # Your Code Here\n",
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data = validation_generator,\n",
        "                              steps_per_epoch = 60,\n",
        "                              epochs = 100,\n",
        "                              validation_steps = 15,\n",
        "                              verbose = 2, \n",
        "                              callbacks = [callbacks])# Your Code Here)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0417 - acc: 0.9899 - val_loss: 0.1993 - val_acc: 0.9764\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.1909 - val_acc: 0.9696\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0161 - acc: 0.9957 - val_loss: 0.2664 - val_acc: 0.9662\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0335 - acc: 0.9908 - val_loss: 0.4936 - val_acc: 0.9459\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0347 - acc: 0.9890 - val_loss: 0.5604 - val_acc: 0.9527\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0164 - acc: 0.9940 - val_loss: 0.3975 - val_acc: 0.9561\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0131 - acc: 0.9966 - val_loss: 0.4289 - val_acc: 0.9595\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0231 - acc: 0.9923 - val_loss: 0.1932 - val_acc: 0.9797\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0118 - acc: 0.9958 - val_loss: 0.2070 - val_acc: 0.9696\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0078 - acc: 0.9966 - val_loss: 0.4816 - val_acc: 0.9527\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0208 - acc: 0.9950 - val_loss: 0.6681 - val_acc: 0.9493\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0365 - acc: 0.9889 - val_loss: 0.7066 - val_acc: 0.9527\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0269 - acc: 0.9933 - val_loss: 0.4770 - val_acc: 0.9595\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0134 - acc: 0.9949 - val_loss: 0.1594 - val_acc: 0.9730\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0301 - acc: 0.9949 - val_loss: 0.1295 - val_acc: 0.9899\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0064 - acc: 0.9975 - val_loss: 0.2137 - val_acc: 0.9764\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0303 - acc: 0.9949 - val_loss: 0.5140 - val_acc: 0.9561\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0165 - acc: 0.9966 - val_loss: 0.2514 - val_acc: 0.9730\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0314 - acc: 0.9967 - val_loss: 0.2926 - val_acc: 0.9730\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0271 - acc: 0.9949 - val_loss: 0.3051 - val_acc: 0.9696\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0478 - acc: 0.9916 - val_loss: 0.2273 - val_acc: 0.9764\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0110 - acc: 0.9958 - val_loss: 0.4853 - val_acc: 0.9628\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0138 - acc: 0.9983 - val_loss: 0.4333 - val_acc: 0.9595\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0097 - acc: 0.9966 - val_loss: 0.2020 - val_acc: 0.9730\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0172 - acc: 0.9958 - val_loss: 0.1670 - val_acc: 0.9730\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0130 - acc: 0.9949 - val_loss: 0.3919 - val_acc: 0.9595\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0095 - acc: 0.9966 - val_loss: 0.1661 - val_acc: 0.9797\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0158 - acc: 0.9933 - val_loss: 0.2523 - val_acc: 0.9696\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0300 - acc: 0.9941 - val_loss: 0.1972 - val_acc: 0.9764\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0080 - acc: 0.9966 - val_loss: 0.5913 - val_acc: 0.9595\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0164 - acc: 0.9958 - val_loss: 0.4359 - val_acc: 0.9628\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0116 - acc: 0.9958 - val_loss: 0.1666 - val_acc: 0.9797\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0106 - acc: 0.9975 - val_loss: 0.3457 - val_acc: 0.9628\n",
            "Epoch 34/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0111 - acc: 0.9983 - val_loss: 0.2928 - val_acc: 0.9730\n",
            "Epoch 35/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0068 - acc: 0.9975 - val_loss: 0.3192 - val_acc: 0.9696\n",
            "Epoch 36/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0040 - acc: 0.9983 - val_loss: 0.7175 - val_acc: 0.9561\n",
            "Epoch 37/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0206 - acc: 0.9966 - val_loss: 0.4492 - val_acc: 0.9595\n",
            "Epoch 38/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0086 - acc: 0.9975 - val_loss: 1.0645 - val_acc: 0.9459\n",
            "Epoch 39/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0169 - acc: 0.9958 - val_loss: 0.2334 - val_acc: 0.9730\n",
            "Epoch 40/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0289 - acc: 0.9915 - val_loss: 0.8020 - val_acc: 0.9561\n",
            "Epoch 41/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0395 - acc: 0.9907 - val_loss: 0.5638 - val_acc: 0.9561\n",
            "Epoch 42/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0222 - acc: 0.9933 - val_loss: 1.1551 - val_acc: 0.9459\n",
            "Epoch 43/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0115 - acc: 0.9983 - val_loss: 0.8940 - val_acc: 0.9527\n",
            "Epoch 44/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0220 - acc: 0.9941 - val_loss: 0.9563 - val_acc: 0.9459\n",
            "Epoch 45/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0220 - acc: 0.9941 - val_loss: 0.7420 - val_acc: 0.9527\n",
            "Epoch 46/100\n",
            "Epoch 1/100\n",
            "60/60 - 13s - loss: 0.0089 - acc: 0.9966 - val_loss: 1.1676 - val_acc: 0.9426\n",
            "Epoch 47/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0086 - acc: 0.9983 - val_loss: 0.6147 - val_acc: 0.9561\n",
            "Epoch 48/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0378 - acc: 0.9957 - val_loss: 1.2151 - val_acc: 0.9358\n",
            "Epoch 49/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0207 - acc: 0.9941 - val_loss: 1.0952 - val_acc: 0.9426\n",
            "Epoch 50/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0107 - acc: 0.9967 - val_loss: 1.0954 - val_acc: 0.9392\n",
            "Epoch 51/100\n",
            "Epoch 1/100\n",
            "60/60 - 12s - loss: 0.0238 - acc: 0.9957 - val_loss: 0.9900 - val_acc: 0.9493\n",
            "Epoch 52/100\n",
            "Epoch 1/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "60/60 - 13s - loss: 0.0013 - acc: 0.9992 - val_loss: 0.9982 - val_acc: 0.9426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "14ce55cf-0cce-455c-df19-91ef46bcfea8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nORe4/wJhpaVEDhUiqAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJsjOtyFgknh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}